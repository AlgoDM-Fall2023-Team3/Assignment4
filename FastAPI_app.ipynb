{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNscPVnCTmHN",
        "outputId": "f78a7850-150e-48dd-f167-3e747e0d2946"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (4.5.0)\n",
            "Collecting typing-extensions\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: typing-extensions\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed typing-extensions-4.8.0\n",
            "Collecting fastapi\n",
            "  Downloading fastapi-0.104.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi) (3.7.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (1.10.13)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi) (1.1.3)\n",
            "Installing collected packages: starlette, fastapi\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fastapi-0.104.1 starlette-0.27.0\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.29.3-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.33.0,>=1.32.3 (from boto3)\n",
            "  Downloading botocore-1.32.3-py3-none-any.whl (11.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.8.0,>=0.7.0 (from boto3)\n",
            "  Downloading s3transfer-0.7.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.33.0,>=1.32.3->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.33.0,>=1.32.3->boto3) (2.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.33.0,>=1.32.3->boto3) (1.16.0)\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.29.3 botocore-1.32.3 jmespath-1.0.1 s3transfer-0.7.0\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.0.1.tar.gz (731 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.8/731.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-7.0.1-py3-none-any.whl size=21122 sha256=c499d8e9d4240eab2590bc0245bbf1a8784c017a93d26e06d6193e83c65d5bd9\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/32/0e/27789b6fde02bf2b320d6f1a0fd9e1354b257c5f75eefc29bc\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.0.1\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.24.0.post1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (4.8.0)\n",
            "Installing collected packages: h11, uvicorn\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 uvicorn-0.24.0.post1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade typing-extensions\n",
        "!pip install --upgrade fastapi\n",
        "!pip install boto3\n",
        "!pip3 install pyngrok\n",
        "!pip3 install uvicorn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FMM1toiKpaX1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from fastapi import FastAPI\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import boto3\n",
        "from io import BytesIO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alUGs1YwTpMx",
        "outputId": "dc48f703-797c-43b4-af61-172f0b0ceb18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Images loaded: 316\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Replace these values with your AWS credentials and bucket information\n",
        "aws_access_key_id = 'AWS_ACCESS_KEY_ID'\n",
        "aws_secret_access_key = 'AWS_SECRET_ACCESS_KEY'\n",
        "\n",
        "# Set the S3 bucket and folder path\n",
        "s3_bucket_name = 'team3-ass3'\n",
        "\n",
        "\n",
        "# Create a session using your AWS credentials\n",
        "session = boto3.Session(\n",
        "    aws_access_key_id=aws_access_key_id,\n",
        "    aws_secret_access_key=aws_secret_access_key,\n",
        ")\n",
        "\n",
        "# Create an S3 client using the session\n",
        "s3_client = session.client('s3')\n",
        "\n",
        "# Specify the S3 object keys for download\n",
        "image_ids_s3_key = f\"image_ids.csv\"\n",
        "features_s3_key = f\"features.npy\"\n",
        "\n",
        "# Download the files from S3\n",
        "image_ids_obj = s3_client.get_object(Bucket=s3_bucket_name, Key=image_ids_s3_key)\n",
        "features_obj = s3_client.get_object(Bucket=s3_bucket_name, Key=features_s3_key)\n",
        "\n",
        "# Load the image IDs\n",
        "image_ids = pd.read_csv(BytesIO(image_ids_obj['Body'].read()))['image_id'].tolist()\n",
        "local_csv_path = 'image_ids.csv'\n",
        "image_ids_df = pd.DataFrame({'image_id': image_ids})\n",
        "image_ids_df.to_csv(local_csv_path, index=False)\n",
        "\n",
        "# Load the features vectors\n",
        "features = np.load(BytesIO(features_obj['Body'].read()))\n",
        "np.save('features.npy', features)\n",
        "\n",
        "# Convert features to Tensors: Float32 on CPU and Float16 on GPU\n",
        "device = \"cpu\"  # Change this to \"cuda\" if using GPU\n",
        "if device == \"cpu\":\n",
        "    image_features = torch.from_numpy(features).float().to(device)\n",
        "else:\n",
        "    image_features = torch.from_numpy(features).to(device)\n",
        "\n",
        "# Print some statistics\n",
        "print(f\"Images loaded: {len(image_ids)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egYNfR8pYUUn",
        "outputId": "7c8d3522-7d1b-49c3-8de3-9e392c48ebd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-tu0wd1ts\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-tu0wd1ts\n",
            "  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy (from clip==1.0)\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.66.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.16.0+cu118)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.10)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.8.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->clip==1.0) (1.3.0)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369500 sha256=b2d52ed5dbac99ca4915491284f4f036df0ac4bba70a1557efe8853625ce5bf3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gaziaf1v/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n",
            "Successfully built clip\n",
            "Installing collected packages: ftfy, clip\n",
            "Successfully installed clip-1.0 ftfy-6.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade git+https://github.com/openai/CLIP.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "vfJ91XVkWc7X"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI, HTTPException, File, UploadFile\n",
        "from fastapi.responses import StreamingResponse\n",
        "import io\n",
        "import boto3\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import clip\n",
        "import base64\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Load the CLIP model\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "\n",
        "s3_folder_path = 'image'\n",
        "app = FastAPI()\n",
        "\n",
        "def encode_search_query(search_query):\n",
        "    print(f\"Type of search_query: {type(search_query)}\")\n",
        "    with torch.no_grad():\n",
        "        # Encode and normalize the search query using CLIP\n",
        "        text_encoded = model.encode_text(clip.tokenize(search_query).to(device))\n",
        "        text_encoded /= text_encoded.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    # Retrieve the feature vector\n",
        "    #print(text_encoded)\n",
        "    print(f\"Text Encoded Type: {type(text_encoded)}\")\n",
        "    return text_encoded\n",
        "\n",
        "\n",
        "def encode_image(image_bytes):\n",
        "    # Encode and normalize the image using CLIP'\n",
        "    image = Image.open(io.BytesIO(image_bytes)).convert('RGB')\n",
        "    #image = Image.open(image_file).convert('RGB')\n",
        "    image_input = preprocess(image).unsqueeze(0).to(device)\n",
        "    image_features = model.encode_image(image_input)\n",
        "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    return image_features\n",
        "\n",
        "\n",
        "def find_best_matches(text_features, image_features, image_ids, results_count=3):\n",
        "  # Compute the similarity between the search query and each image using the Cosine similarity\n",
        "    similarities = (image_features @ text_features.T).squeeze(1)\n",
        "\n",
        "    # Sort the images by their similarity score\n",
        "    best_image_idx = (-similarities).argsort()\n",
        "\n",
        "    # Return the image IDs of the best matches\n",
        "    return [image_ids[i] for i in best_image_idx[:results_count]]\n",
        "\n",
        "def find_similar_images(uploaded_image_features, image_features, image_ids, results_count=3):\n",
        "    cos = torch.nn.CosineSimilarity(dim=0)\n",
        "\n",
        "    # Calculate cosine similarities between the uploaded image and all other images\n",
        "    similarities = cos(uploaded_image_features.unsqueeze(0), image_features)\n",
        "\n",
        "    # Create a list of tuples containing similarity values and corresponding image indices\n",
        "    similarities_with_indices = list(zip(similarities.tolist(), range(len(similarities))))\n",
        "\n",
        "    # Sort the list based on similarity values in descending order\n",
        "    sorted_similarities = sorted(similarities_with_indices, key=lambda x: x[0], reverse=True)\n",
        "\n",
        "    # Take the top N indices\n",
        "    best_image_indices = [i for _, i in sorted_similarities[:results_count]]\n",
        "    print(sorted_similarities)\n",
        "    print(type(sorted_similarities))\n",
        "\n",
        "    # Return the image IDs of the best matches\n",
        "    return [image_ids[i] for i in best_image_indices]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def search(search_query, image_features, image_ids, s3_bucket_name, s3_folder_path, results_count=3):\n",
        "    # Encode the search query\n",
        "    text_features = encode_search_query(search_query)\n",
        "\n",
        "    # Find the best matches\n",
        "    return find_best_matches(text_features, image_features, image_ids, results_count)\n",
        "\n",
        "\n",
        "def search_by_image(image_file, image_features, image_ids,s3_bucket_name, s3_folder_path, results_count):\n",
        "    # Encode the uploaded image\n",
        "    image_bytes = base64.b64decode(image_file)\n",
        "\n",
        "    uploaded_image_features = encode_image(image_bytes)\n",
        "    # Find similar images\n",
        "\n",
        "    return find_similar_images(uploaded_image_features, image_features, image_ids, results_count)\n",
        "\n",
        "@app.get(\"/\")\n",
        "def read_root():\n",
        "    return {\"message\": \"Welcome to the image search API!\"}\n",
        "\n",
        "@app.post(\"/search_images_by_text/\")\n",
        "async def search_images_by_text(request:dict):\n",
        "    search_query = request['search_query']\n",
        "    results_count = request['results_count']\n",
        "\n",
        "    result_image_ids = search(search_query, image_features, image_ids, s3_bucket_name, s3_folder_path, results_count)\n",
        "    image_paths = [f\"{s3_folder_path}/{image_id}.jpg\" for image_id in result_image_ids]\n",
        "\n",
        "    images = []\n",
        "    for image_path in image_paths:\n",
        "        image_bytes = download_image_from_s3(s3_bucket_name, image_path)\n",
        "        images.append(image_bytes)\n",
        "\n",
        "    def image_generator():\n",
        "        for image_bytes in images:\n",
        "            yield image_bytes\n",
        "    return StreamingResponse(image_generator(), media_type=\"image/jpeg\")\n",
        "\n",
        "# @app.post(\"/search_images_by_image/\")\n",
        "# async def search_images_by_image(request:dict):\n",
        "\n",
        "#       image_file = request.get('image_file')\n",
        "#       results_count = request.get('results_count')\n",
        "#       result_images = search_by_image(image_file, image_features, image_ids, s3_bucket_name, s3_folder_path,results_count)\n",
        "#       image_paths = [f\"{s3_folder_path}/{image_id}.jpg\" for image_id in result_images]\n",
        "\n",
        "#       images = []\n",
        "#       for image_path in image_paths:\n",
        "#           image_bytes = download_image_from_s3(s3_bucket_name, image_path)\n",
        "#           images.append(image_bytes)\n",
        "#           print(image_path)\n",
        "#       print(len(images))\n",
        "#       def image_generator():\n",
        "#           for image_bytes in images:\n",
        "#               yield image_bytes\n",
        "\n",
        "#       return StreamingResponse(image_generator(), media_type=\"image/jpeg\")\n",
        "\n",
        "@app.post(\"/search_images_by_image/\")\n",
        "async def search_images_by_image(request:dict):\n",
        "\n",
        "      image_file = request.get('image_file')\n",
        "      results_count = request.get('results_count')\n",
        "      result_images = search_by_image(image_file, image_features, image_ids, s3_bucket_name, s3_folder_path,results_count)\n",
        "      image_paths = [f\"{s3_folder_path}/{image_id}.jpg\" for image_id in result_images]\n",
        "\n",
        "      images = []\n",
        "      for image_path in image_paths:\n",
        "          image_bytes = download_image_from_s3(s3_bucket_name, image_path)\n",
        "          images.append(image_bytes)\n",
        "          print(image_path)\n",
        "      print(len(images))\n",
        "\n",
        "      # Use a custom separator to join image data\n",
        "      custom_separator = b'YOUR_CUSTOM_SEPARATOR'\n",
        "      joined_image_data = custom_separator.join(images)\n",
        "      def image_generator():\n",
        "          for image_bytes in images:\n",
        "              yield joined_image_data\n",
        "\n",
        "      return StreamingResponse(image_generator(), media_type=\"image/jpeg\")\n",
        "\n",
        "def download_image_from_s3(bucket_name, image_key):\n",
        "    s3 = boto3.client('s3', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key)\n",
        "    image_bytes = s3.get_object(Bucket=bucket_name, Key=image_key)['Body'].read()\n",
        "    return image_bytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE5TlPyKY9z2",
        "outputId": "33d594d3-d989-4a2e-a020-d33bc932e879"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-11-18T04:56:12+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Public URL: https://e161-35-196-84-171.ngrok-free.app\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [204]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     34.147.60.76:0 - \"POST /search_images_by_image HTTP/1.1\" 307 Temporary Redirect\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image/sh401_3_back.jpg\n",
            "image/swe02_2_side.jpg\n",
            "image/jv201_6_flat.jpg\n",
            "3\n",
            "INFO:     34.147.60.76:0 - \"POST /search_images_by_image/ HTTP/1.1\" 200 OK\n",
            "INFO:     34.147.60.76:0 - \"POST /search_images_by_image HTTP/1.1\" 307 Temporary Redirect\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image/den601_29_2_side.jpg\n",
            "image/p101_3_back.jpg\n",
            "image/15_2_side.jpg\n",
            "3\n",
            "INFO:     34.147.60.76:0 - \"POST /search_images_by_image/ HTTP/1.1\" 200 OK\n",
            "INFO:     34.147.60.76:0 - \"POST /search_images_by_image HTTP/1.1\" 307 Temporary Redirect\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image/den601_29_2_side.jpg\n",
            "image/p101_3_back.jpg\n",
            "image/15_2_side.jpg\n",
            "3\n",
            "INFO:     34.147.60.76:0 - \"POST /search_images_by_image/ HTTP/1.1\" 200 OK\n",
            "INFO:     34.147.60.76:0 - \"POST /search_images_by_image HTTP/1.1\" 307 Temporary Redirect\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image/sh401_3_back.jpg\n",
            "image/swe02_2_side.jpg\n",
            "image/jv201_6_flat.jpg\n",
            "3\n",
            "INFO:     34.147.60.76:0 - \"POST /search_images_by_image/ HTTP/1.1\" 200 OK\n",
            "INFO:     34.147.60.76:0 - \"POST /search_images_by_image HTTP/1.1\" 307 Temporary Redirect\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image/den601_29_2_side.jpg\n",
            "image/p101_3_back.jpg\n",
            "image/15_2_side.jpg\n",
            "3\n",
            "INFO:     34.147.60.76:0 - \"POST /search_images_by_image/ HTTP/1.1\" 200 OK\n",
            "INFO:     34.147.60.76:0 - \"POST /search_images_by_image HTTP/1.1\" 307 Temporary Redirect\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image/den601_29_2_side.jpg\n",
            "image/p101_3_back.jpg\n",
            "image/15_2_side.jpg\n",
            "3\n",
            "INFO:     34.147.60.76:0 - \"POST /search_images_by_image/ HTTP/1.1\" 200 OK\n",
            "INFO:     34.147.60.76:0 - \"POST /search_images_by_image HTTP/1.1\" 307 Temporary Redirect\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image/den601_29_2_side.jpg\n",
            "image/p101_3_back.jpg\n",
            "image/15_2_side.jpg\n",
            "3\n",
            "INFO:     34.147.60.76:0 - \"POST /search_images_by_image/ HTTP/1.1\" 200 OK\n",
            "INFO:     34.147.60.76:0 - \"POST /search_images_by_image HTTP/1.1\" 307 Temporary Redirect\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image/den601_29_2_side.jpg\n",
            "image/p101_3_back.jpg\n",
            "image/15_2_side.jpg\n",
            "3\n",
            "INFO:     34.147.60.76:0 - \"POST /search_images_by_image/ HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [204]\n"
          ]
        }
      ],
      "source": [
        "from fastapi import FastAPI\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "\n",
        "!ngrok authtoken ngrok-token\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aT6N_j58eOHv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
