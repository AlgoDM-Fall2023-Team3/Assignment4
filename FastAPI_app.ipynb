{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNscPVnCTmHN",
        "outputId": "9e2987aa-cb24-4686-e367-9bc43953ab09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (4.8.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (0.104.1)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi) (3.7.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (1.10.13)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.27.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi) (1.1.3)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (1.29.0)\n",
            "Requirement already satisfied: botocore<1.33.0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.32.0)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from boto3) (0.7.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.33.0,>=1.32.0->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.33.0,>=1.32.0->boto3) (2.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.33.0,>=1.32.0->boto3) (1.16.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.0.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (0.24.0.post1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (4.8.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade typing-extensions\n",
        "!pip install --upgrade fastapi\n",
        "!pip install boto3\n",
        "!pip3 install pyngrok\n",
        "!pip3 install uvicorn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from fastapi import FastAPI\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import boto3\n",
        "from io import BytesIO"
      ],
      "metadata": {
        "id": "FMM1toiKpaX1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Replace these values with your AWS credentials and bucket information\n",
        "aws_access_key_id = 'AKIA4ZOP2NKKEIJE2JUZ'\n",
        "aws_secret_access_key = 'YcDzF+fI0EwiomwODUQgLsOAhRBBYg2p9aneXbqG'\n",
        "\n",
        "# Set the S3 bucket and folder path\n",
        "s3_bucket_name = 'team3-ass3'\n",
        "\n",
        "\n",
        "# Create a session using your AWS credentials\n",
        "session = boto3.Session(\n",
        "    aws_access_key_id=aws_access_key_id,\n",
        "    aws_secret_access_key=aws_secret_access_key,\n",
        ")\n",
        "\n",
        "# Create an S3 client using the session\n",
        "s3_client = session.client('s3')\n",
        "\n",
        "# Specify the S3 object keys for download\n",
        "image_ids_s3_key = f\"image_ids.csv\"\n",
        "features_s3_key = f\"features.npy\"\n",
        "\n",
        "# Download the files from S3\n",
        "image_ids_obj = s3_client.get_object(Bucket=s3_bucket_name, Key=image_ids_s3_key)\n",
        "features_obj = s3_client.get_object(Bucket=s3_bucket_name, Key=features_s3_key)\n",
        "\n",
        "# Load the image IDs\n",
        "image_ids = pd.read_csv(BytesIO(image_ids_obj['Body'].read()))['image_id'].tolist()\n",
        "local_csv_path = 'image_ids.csv'\n",
        "image_ids_df = pd.DataFrame({'image_id': image_ids})\n",
        "image_ids_df.to_csv(local_csv_path, index=False)\n",
        "\n",
        "# Load the features vectors\n",
        "features = np.load(BytesIO(features_obj['Body'].read()))\n",
        "np.save('features.npy', features)\n",
        "\n",
        "# Convert features to Tensors: Float32 on CPU and Float16 on GPU\n",
        "device = \"cpu\"  # Change this to \"cuda\" if using GPU\n",
        "if device == \"cpu\":\n",
        "    image_features = torch.from_numpy(features).float().to(device)\n",
        "else:\n",
        "    image_features = torch.from_numpy(features).to(device)\n",
        "\n",
        "# Print some statistics\n",
        "print(f\"Images loaded: {len(image_ids)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alUGs1YwTpMx",
        "outputId": "3baed2c3-8438-4698-f674-f631671f1398"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images loaded: 316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade git+https://github.com/openai/CLIP.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egYNfR8pYUUn",
        "outputId": "ca35b46f-6502-4917-e779-ecdd73751481"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-4a_52109\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-4a_52109\n",
            "  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (6.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.66.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.16.0+cu118)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.8.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->clip==1.0) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI, HTTPException, File, UploadFile\n",
        "from fastapi.responses import StreamingResponse\n",
        "import io\n",
        "import boto3\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import clip\n",
        "\n",
        "# Load the CLIP model\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "\n",
        "s3_folder_path = 'image'\n",
        "app = FastAPI()\n",
        "\n",
        "def encode_search_query(search_query):\n",
        "    print(f\"Type of search_query: {type(search_query)}\")\n",
        "    with torch.no_grad():\n",
        "        # Encode and normalize the search query using CLIP\n",
        "        text_encoded = model.encode_text(clip.tokenize(search_query).to(device))\n",
        "        text_encoded /= text_encoded.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    # Retrieve the feature vector\n",
        "    #print(text_encoded)\n",
        "    print(f\"Text Encoded Type: {type(text_encoded)}\")\n",
        "    return text_encoded\n",
        "\n",
        "\n",
        "def find_best_matches(text_features, image_features, image_ids, results_count=3):\n",
        "  # Compute the similarity between the search query and each image using the Cosine similarity\n",
        "    similarities = (image_features @ text_features.T).squeeze(1)\n",
        "\n",
        "    # Sort the images by their similarity score\n",
        "    best_image_idx = (-similarities).argsort()\n",
        "\n",
        "    # Return the image IDs of the best matches\n",
        "    return [image_ids[i] for i in best_image_idx[:results_count]]\n",
        "\n",
        "def search(search_query, image_features, image_ids, s3_bucket_name, s3_folder_path, results_count=3):\n",
        "    # Encode the search query\n",
        "    text_features = encode_search_query(search_query)\n",
        "\n",
        "    # Find the best matches\n",
        "    return find_best_matches(text_features, image_features, image_ids, results_count)\n",
        "\n",
        "@app.get(\"/\")\n",
        "def read_root():\n",
        "    return {\"message\": \"Welcome to the image search API!\"}\n",
        "\n",
        "@app.post(\"/search_images/\")\n",
        "async def search_images(request:dict):\n",
        "    print(request)\n",
        "    search_query = request['search_query']\n",
        "    results_count = request['results_count']\n",
        "    result_image_ids = search(search_query, image_features, image_ids, s3_bucket_name, s3_folder_path, results_count)\n",
        "\n",
        "    image_paths = [f\"{s3_folder_path}/{image_id}.jpg\" for image_id in result_image_ids]\n",
        "\n",
        "    images = []\n",
        "    for image_path in image_paths:\n",
        "        image_bytes = download_image_from_s3(s3_bucket_name, image_path)\n",
        "        images.append(image_bytes)\n",
        "\n",
        "    def image_generator():\n",
        "        for image_bytes in images:\n",
        "            yield image_bytes\n",
        "\n",
        "    return StreamingResponse(image_generator(), media_type=\"image/jpeg\")\n",
        "\n",
        "def download_image_from_s3(bucket_name, image_key):\n",
        "    s3 = boto3.client('s3', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key)\n",
        "    image_bytes = s3.get_object(Bucket=bucket_name, Key=image_key)['Body'].read()\n",
        "    return image_bytes"
      ],
      "metadata": {
        "id": "vfJ91XVkWc7X"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "\n",
        "!ngrok authtoken 2YDoEkjvj9KuJ98vnKuos99bOPf_5xvBJ8K57uADTJJgebWsG\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE5TlPyKY9z2",
        "outputId": "7a02e334-6a32-4cc5-9101-03154cdb10f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-11-15T20:00:19+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://608f-35-185-40-207.ngrok-free.app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [451]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     35.245.102.208:0 - \"POST /search_images HTTP/1.1\" 307 Temporary Redirect\n",
            "{'search_query': 'white shirt', 'results_count': 1}\n",
            "Type of search_query: <class 'str'>\n",
            "Text Encoded Type: <class 'torch.Tensor'>\n",
            "INFO:     35.245.102.208:0 - \"POST /search_images/ HTTP/1.1\" 200 OK\n",
            "INFO:     35.245.102.208:0 - \"POST /search_images HTTP/1.1\" 307 Temporary Redirect\n",
            "{'search_query': 'white trouser', 'results_count': 1}\n",
            "Type of search_query: <class 'str'>\n",
            "Text Encoded Type: <class 'torch.Tensor'>\n",
            "INFO:     35.245.102.208:0 - \"POST /search_images/ HTTP/1.1\" 200 OK\n",
            "INFO:     35.245.102.208:0 - \"POST /search_images HTTP/1.1\" 307 Temporary Redirect\n",
            "{'search_query': 'grey trouser', 'results_count': 1}\n",
            "Type of search_query: <class 'str'>\n",
            "Text Encoded Type: <class 'torch.Tensor'>\n",
            "INFO:     35.245.102.208:0 - \"POST /search_images/ HTTP/1.1\" 200 OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aT6N_j58eOHv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}